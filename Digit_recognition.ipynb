{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "apKwXWL2YnkC"
   },
   "source": [
    "# **Import Required Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "M01EZ0rKVYK9"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m  \u001b[38;5;66;03m# Import TensorFlow library\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layers, models  \u001b[38;5;66;03m# Import necessary Keras modules\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m  \u001b[38;5;66;03m# Import NumPy for numerical operations\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf  # Import TensorFlow library\n",
    "from tensorflow.keras import layers, models  # Import necessary Keras modules\n",
    "import numpy as np  # Import NumPy for numerical operations\n",
    "import matplotlib.pyplot as plt  # Import Matplotlib for visualization\n",
    "from tensorflow.keras.utils import to_categorical  # Import function for one-hot encoding labels\n",
    "from sklearn.model_selection import train_test_split  # Import function for splitting dataset\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator  # Import image data augmentation tool\n",
    "from tensorflow.keras.models import load_model  # Import function to load a saved model\n",
    "from PIL import Image  # Import Python Imaging Library for image processing\n",
    "from google.colab import files  # Import Colab files module to upload images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "piKnNoRZY_Nn"
   },
   "source": [
    "# **Load and Preprocess the MNIST Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lcHu8xHLVe2G",
    "outputId": "06cbdd21-d39c-4dae-d6d4-7451f1cc505a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 60000, Testing samples: 10000\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "print(f\"Training samples: {x_train.shape[0]}, Testing samples: {x_test.shape[0]}\")  # Print dataset size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LK6E4i-KVo5w",
    "outputId": "d8f2eb14-c4d4-4bcb-f80b-c8cbdd1aad6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resized training shape: (60000, 32, 32), Testing shape: (10000, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "# Resize images to 32x32\n",
    "x_train_resized = np.array([tf.image.resize(img[..., np.newaxis], (32, 32)).numpy().squeeze() for img in x_train])\n",
    "x_test_resized = np.array([tf.image.resize(img[..., np.newaxis], (32, 32)).numpy().squeeze() for img in x_test])\n",
    "\n",
    "print(f\"Resized training shape: {x_train_resized.shape}, Testing shape: {x_test_resized.shape}\")  # Print resized shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "k_RdCWsAVwxE"
   },
   "outputs": [],
   "source": [
    "# Normalize images (pixel values between 0 and 1)\n",
    "x_train_resized = x_train_resized / 255.0\n",
    "x_test_resized = x_test_resized / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9jEGAasLZQMk"
   },
   "source": [
    "**Split Dataset into Training and Validation Sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_OujqVfsV1mK",
    "outputId": "8b418e97-114f-408a-ae7b-0674c59c6cb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape: (48000, 32, 32), Validation shape: (12000, 32, 32), Testing shape: (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Split dataset: 80% training, 20% validation\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_resized, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training shape: {x_train.shape}, Validation shape: {x_val.shape}, Testing shape: {x_test.shape}\")  # Print final dataset shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2IrqxxU-V6kM",
    "outputId": "fc37dc16-e2c4-4660-aeef-059b835bf8e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample one-hot encoded label: [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# One-hot encode labels (convert labels into categorical format for multi-class classification)\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_val = to_categorical(y_val, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "print(f\"Sample one-hot encoded label: {y_train[0]}\")  # Print an example one-hot encoded label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jlel1V1tZdy8"
   },
   "source": [
    "**Define Data Augmentation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6IK7uzBIV-6E"
   },
   "outputs": [],
   "source": [
    "# Improved Data augmentation\n",
    "data_augmentation = ImageDataGenerator(\n",
    "    rotation_range=15,  # Increased rotation range\n",
    "    width_shift_range=0.15,  # Increased shift range\n",
    "    height_shift_range=0.15,\n",
    "    shear_range=0.15,  # Shear transformation\n",
    "    zoom_range=0.2  # Increased zoom\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pbqg8QQCZoa3"
   },
   "source": [
    "# **Build the CNN Model**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "eRj_KBdpWCyo"
   },
   "outputs": [],
   "source": [
    "# Build improved CNN model\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 1), kernel_regularizer=tf.keras.regularizers.l2(0.001)),  # L2 Regularization\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.3),  # Dropout to reduce overfitting\n",
    "    layers.Conv2D(64, (3, 3), activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rcJR4HkJaBLJ"
   },
   "source": [
    "# **Training and Compilation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "8TPVGXMbWIfL"
   },
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qzVUAOLrWMPQ",
    "outputId": "5efef50f-6b43-40e4-a3ea-a185d1e5860b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 67ms/step - accuracy: 0.5836 - loss: 1.4507 - val_accuracy: 0.9637 - val_loss: 0.3417\n",
      "Epoch 2/6\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 67ms/step - accuracy: 0.8985 - loss: 0.5536 - val_accuracy: 0.9784 - val_loss: 0.2737\n",
      "Epoch 3/6\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 67ms/step - accuracy: 0.9233 - loss: 0.4482 - val_accuracy: 0.9824 - val_loss: 0.2523\n",
      "Epoch 4/6\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 63ms/step - accuracy: 0.9311 - loss: 0.4102 - val_accuracy: 0.9786 - val_loss: 0.2445\n",
      "Epoch 5/6\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 66ms/step - accuracy: 0.9380 - loss: 0.3760 - val_accuracy: 0.9841 - val_loss: 0.2217\n",
      "Epoch 6/6\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 66ms/step - accuracy: 0.9438 - loss: 0.3563 - val_accuracy: 0.9839 - val_loss: 0.2241\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7e653f84c850>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model with data augmentation\n",
    "model.fit(data_augmentation.flow(x_train[..., np.newaxis], y_train, batch_size=64),  # Apply data augmentation\n",
    "          epochs=6,  # Reduced to 6 epochs\n",
    "          validation_data=(x_val[..., np.newaxis], y_val))  # Validate using validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qorf5JzRaKiR"
   },
   "source": [
    "# **Evaluate Model Performance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ocr42NmPXGSt",
    "outputId": "6b35b76f-22d3-4401-edce-2e0ddf6fd3d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9830 - loss: 0.2222\n",
      "Test accuracy: 0.9867\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model performance\n",
    "test_loss, test_acc = model.evaluate(x_test_resized[..., np.newaxis], y_test)  # Fixed test dataset shape\n",
    "print(f\"Test accuracy: {test_acc:.4f}\")  # Print test accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "So5Fo3NRaZCx"
   },
   "source": [
    "# **Save and Load the Trained Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VEI6fYfOXKVG",
    "outputId": "42545e47-39d7-4fd6-e3c7-6dbac0925fc2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Save the trained model\n",
    "model.save(\"handwriting_cnn_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vGsyc08EXOI_",
    "outputId": "642de524-c883-4e2a-87b0-62b4927c302f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# Load the saved model\n",
    "loaded_model = load_model(\"handwriting_cnn_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tyO7aXMfahHU"
   },
   "source": [
    "# **Predict Custom Handwritten Image**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 110
    },
    "id": "BQo-RX08XRYW",
    "outputId": "8d5a82a9-3246-41d1-d44b-3275998441b6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-9da06886-654d-466c-9ae4-ecc57765246b\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-9da06886-654d-466c-9ae4-ecc57765246b\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving image_2025-02-26_141848598.png to image_2025-02-26_141848598.png\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
      "Predicted digit: 3\n"
     ]
    }
   ],
   "source": [
    "# Function to predict a custom handwritten image\n",
    "def predict_custom_image():\n",
    "    uploaded = files.upload()  # Upload custom image\n",
    "    for filename in uploaded.keys():\n",
    "        image = Image.open(filename).convert('L')  # Convert image to grayscale\n",
    "        image = image.resize((32, 32))  # Resize to 32x32 pixels\n",
    "        image = np.array(image).astype('float32') / 255.0  # Normalize pixel values\n",
    "        image = image.reshape((1, 32, 32, 1))  # Reshape for model input\n",
    "        prediction = model.predict(image)  # Predict digit\n",
    "        print(f'Predicted digit: {np.argmax(prediction)}')  # Print predicted digit\n",
    "\n",
    "predict_custom_image()  # Call function to make a prediction"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
